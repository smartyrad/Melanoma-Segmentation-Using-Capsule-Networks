{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from os.path import join\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Reshape, concatenate, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.backend import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard,RemoteMonitor\n",
    "import tensorflow as tf\n",
    "import ntpath\n",
    "K.clear_session()\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "print(K.image_data_format())\n",
    "smooth = 1e-12\n",
    "num_examples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_size = 512\n",
    "def load_files():\n",
    "    global image_size\n",
    "    global num_examples\n",
    "    mask_images=[]\n",
    "    ori_images = []\n",
    "\n",
    "    mask_path = \"unet_train/gt/*\"\n",
    "    masks = glob.glob(mask_path)\n",
    "    print(\"Loading masks\")\n",
    "    for fl in masks:\n",
    "        train_image = cv2.imread(fl)\n",
    "        shape = train_image.shape\n",
    "        #Supervisely gives 3 images in out and we need the mask only\n",
    "        start = shape[1]//3\n",
    "        start = start * 2\n",
    "        end = shape[1]\n",
    "        train_image = train_image[: , start:end]\n",
    "        train_image = cv2.resize(train_image, (image_size, image_size))\n",
    "        mask_images.append(train_image)\n",
    "    orig_path = \"unet_train/orig/*\"\n",
    "    orig = glob.glob(orig_path)\n",
    "    print(\"loading original\")\n",
    "    for fl in orig:\n",
    "        orig_images = cv2.imread(fl)\n",
    "        orig_images = cv2.resize(orig_images, (image_size, image_size))\n",
    "        ori_images.append(orig_images)\n",
    "    masked = np.array(mask_images)\n",
    "    origi = np.array(ori_images)\n",
    "    num_examples = masked.shape[0]\n",
    "    return masked, origi\n",
    "\n",
    "masks, origi = load_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_shape=(512, 512, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 512\n",
    "\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(inputs)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a = Conv2D(16, (3, 3), padding='same')(down0a)\n",
    "    down0a = BatchNormalization()(down0a)\n",
    "    down0a = Activation('relu')(down0a)\n",
    "    down0a_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0a)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0a_pool)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    # 256\n",
    "\n",
    "    up0a = UpSampling2D((2, 2))(up0)\n",
    "    up0a = concatenate([down0a, up0a], axis=3)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    up0a = Conv2D(16, (3, 3), padding='same')(up0a)\n",
    "    up0a = BatchNormalization()(up0a)\n",
    "    up0a = Activation('relu')(up0a)\n",
    "    # 512\n",
    "\n",
    "    cov10 = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=cov10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def jaccard_coef(y_true, y_pred, smooth=0.0):\n",
    "    '''Average jaccard coefficient per batch.'''\n",
    "    axes = (1,2,3)\n",
    "    intersection = K.sum(y_true * y_pred, axis=axes)\n",
    "    union = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes) - intersection\n",
    "    return K.mean( (intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def unet_loss(y_true, y_pred):\n",
    "    loss = bce_dice_loss(y_true,y_pred) - K.log(jaccard_coef(y_true,y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    \n",
    "    def __init__(self, size, n_cls, batch_size):\n",
    "        self.size = size\n",
    "        self.n_cls = n_cls\n",
    "        self.batch_size = batch_size\n",
    "        self.i = 0\n",
    "    \n",
    "    def get_batch(self):\n",
    "        global masks\n",
    "        global origi\n",
    "        while True:\n",
    "            orig_batch = np.zeros((self.batch_size, self.size, self.size, 3))\n",
    "            gt_batch = np.zeros((self.batch_size, self.size, self.size, 3))\n",
    "            perm = np.arange(num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            msks = [masks[j] for j in perm]\n",
    "            oigi = [origi[j] for j in perm]\n",
    "            for i in range(self.batch_size):\n",
    "                orig_batch[i] = oigi[i]\n",
    "                gt_batch[i] = msks[i]\n",
    "            yield orig_batch, gt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "num_examples = origi.shape[0]\n",
    "batch_size = 4\n",
    "s_tr =np.floor(float(origi.shape[0]) / float(batch_size))\n",
    "#s_val =np.floor(float(v_ori.shape[0]) / float(batch_size))\n",
    "train_batch_generator = BatchGenerator( image_size, 1, batch_size)\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "size = image_size\n",
    "n_cls = 1\n",
    "model = get_unet()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=unet_loss, metrics=['acc'])\n",
    "tensorboard = TensorBoard(log_dir=\"unetlog/\", batch_size=4,write_graph=True)\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4),\n",
    "             RemoteMonitor(root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None),\n",
    "             tensorboard]\n",
    "model.fit_generator(train_batch_generator.get_batch(),steps_per_epoch=s_tr,epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(K)\n",
    "import h5py\n",
    "model.save('modeltr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = cv2.imread(\"1610.png\")\n",
    "shape = train_image.shape\n",
    "train_image = cv2.resize(train_image, (image_size, image_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pic = np.array(train_image)\n",
    "train_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.expand_dims(train_pic, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpo=model.predict(image)\n",
    "#print(mpo)\n",
    "mpo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpo = mpo.reshape(512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(mpo)\n",
    "#plt.savefig('output.png')re\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(mpo, cv2.COLOR_BGR2HSV)\n",
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([110,50,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = cv2.imread('1901.jpg')\n",
    "shape = train_image.shape\n",
    "#Supervisely gives 3 images in out and we need the mask onl\n",
    "start = shape[1]//3\n",
    "end = 2 * start\n",
    "train_image = train_image[: , start:end]\n",
    "train_image = cv2.resize(train_image, (image_size, image_size))\n",
    "print(len(train_image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_image = cv2.imread(\"1903.jpg\")\n",
    "shape = train_image.shape\n",
    "train_image = cv2.resize(train_image, (image_size, image_size))\n",
    "plt.axis('off')\n",
    "plt.imshow(train_image)\n",
    "plt.savefig('input.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model('modeltr.h5', custom_objects={'jaccard_coef_int': jaccard_coef_int,'jaccard_coef_loss': jaccard_coef_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =512\n",
    "train_image = cv2.imread('testing/1384.png')\n",
    "shape = train_image.shape\n",
    "train_image = cv2.resize(train_image, (image_size, image_size))\n",
    "train_pic = np.array(train_image)\n",
    "image = np.expand_dims(train_pic, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.reshape(512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_overlay(image, mask, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Helper function to visualize mask on the top of the car\n",
    "    \"\"\"\n",
    "    mask = np.dstack((mask, mask, mask)) * np.array(color)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    return cv2.addWeighted(mask, 0.5, image, 0.5, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img= cv2.imread('train/boneage-training-dataset/1903.png')\n",
    "img = cv2.resize(img, (512, 512))\n",
    "image = np.expand_dims(img, axis=0)\n",
    "g = model.predict(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.reshape(512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape\n",
    "largestCC = g == np.argmax(np.bincount(g.flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_overlay(img, (g > 0.5).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = g.astype('uint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undesired_objects (image):\n",
    "    image = image.astype('uint8')\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2, nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "\n",
    "    img2 = np.zeros(output.shape)\n",
    "    img2[output == max_label] = 255\n",
    "    cv2.imshow(\"Biggest component\", img2)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label   \n",
    "\n",
    "def getLargestCC(segmentation):\n",
    "    labels = label(segmentation)\n",
    "    largestCC = labels == np.argmax(np.bincount(labels.flat))\n",
    "    return largestCC\n",
    "a = getLargestCC(mpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1-a\n",
    "plt.imshow(a.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g =g.reshape(512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.dtype\n",
    "a =np.finfo(np.float32).min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ball_ycrcb_mint = np.array([0, 90, 100],np.uint8)\n",
    "ball_ycrcb_maxt = np.array([25, 255, 255],np.uint8)\n",
    "ball_ycrcb = cv2.inRange(gray_image, ball_ycrcb_mint, ball_ycrcb_maxt)\n",
    "#cv2.imwrite('Photos/output2.jpg', ball_ycrcb) # Second image\n",
    "areaArray = []\n",
    "count = 1\n",
    "\n",
    "contours, _ = cv2.findContours(ball_ycrcb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i, c in enumerate(contours):\n",
    "    area = cv2.contourArea(c)\n",
    "    areaArray.append(area)\n",
    "\n",
    "#first sort the array by area\n",
    "sorteddata = sorted(zip(areaArray, contours), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "#find the nth largest contour [n-1][1], in this case 2\n",
    "secondlargestcontour = sorteddata[1][1]\n",
    "\n",
    "#draw it\n",
    "x, y, w, h = cv2.boundingRect(secondlargestcontour)\n",
    "cv2.drawContours(im, secondlargestcontour, -1, (255, 0, 0), 2)\n",
    "cv2.rectangle(im, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "cv2.imwrite('Photos/output3.jpg', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(gray_image, 127, 255, 0)\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, -1, (0,255,0), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread('1903.png')\n",
    "arr = np.uint8(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = cv2.resize(a, (image_size, image_size))\n",
    "train_image = np.expand_dims(train_image, axis=0)\n",
    "dk=model.predict(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.uint8(dk*255)\n",
    "a= a.reshape(512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the image\n",
    "p = cv2.imread('train/boneage-training-dataset/1384.png')\n",
    "train_image = cv2.resize(p, (image_size, image_size))\n",
    "train_image = np.expand_dims(train_image, axis=0)\n",
    "dk=model.predict(train_image)\n",
    "a= np.uint8(dk*255)\n",
    "a= a.reshape(512,512,3)\n",
    "gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "mask = np.ones((512,512), dtype=\"uint8\") * 255\n",
    "\n",
    "_, contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i, c in enumerate(contours):\n",
    "    area = cv2.contourArea(c)\n",
    "    if area < 90000:\n",
    "        cv2.drawContours(mask, [c], -1, 0, -1)\n",
    "\n",
    "image = cv2.bitwise_and(a, a, mask=mask)    \n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_ycrcb_mint = np.array([0, 90, 100],np.uint8)\n",
    "ball_ycrcb_maxt = np.array([25, 255, 255],np.uint8)\n",
    "ball_ycrcb = cv2.inRange(im_ycrcb, ball_ycrcb_mint, ball_ycrcb_maxt)\n",
    "#cv2.imwrite('Photos/output2.jpg', ball_ycrcb) # Second image\n",
    "areaArray = []\n",
    "count = 1\n",
    "\n",
    "contours, _ = cv2.findContours(ball_ycrcb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i, c in enumerate(contours):\n",
    "    area = cv2.contourArea(c)\n",
    "    areaArray.append(area)\n",
    "\n",
    "#first sort the array by area\n",
    "sorteddata = sorted(zip(areaArray, contours), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "#find the nth largest contour [n-1][1], in this case 2\n",
    "secondlargestcontour = sorteddata[1][1]\n",
    "\n",
    "#draw it\n",
    "x, y, w, h = cv2.boundingRect(secondlargestcontour)\n",
    "cv2.drawContours(im, secondlargestcontour, -1, (255, 0, 0), 2)\n",
    "cv2.rectangle(im, (x, y), (x+w, y+h), (0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.zeros_like(arr)                                        # step 1\n",
    "for val in np.unique(arr)[1:]:                                      # step 2\n",
    "    mask = np.uint8(img == val)                                     # step 3\n",
    "    labels, stats = cv2.connectedComponentsWithStats(mask, 4)[1:3]  # step 4\n",
    "    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])      # step 5\n",
    "    new_img[labels == largest_label] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model.predict(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(50, 50))\n",
    "columns = 2\n",
    "rows = 1\n",
    "img = p\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(img)\n",
    "plt.savefig('mamos.png')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(a)\n",
    "plt.title('image_test',fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = cv2.imread('1901.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "shape = train_image.shape\n",
    "        #Supervisely gives 3 images in out and we need the mask only\n",
    "start = shape[1]//3\n",
    "start = start * 2\n",
    "end = shape[1]\n",
    "train_image = train_image[: , start:end]\n",
    "print(train_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(train_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "(thresh, im_bw) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = cv2.imread('1901.jpg')\n",
    "shape = q.shape\n",
    "        #Supervisely gives 3 images in out and we need the mask only\n",
    "start = shape[1]//3\n",
    "#start = start * 2\n",
    "end = start * 2\n",
    "train_image = q[: , start:end]\n",
    "im_gray = cv2.cvtColor(train_image, cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh1 = cv2.threshold(im_gray,127,1,cv2.THRESH_BINARY)\n",
    "backtorgb = cv2.cvtColor(thresh1,cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(backtorgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(set( tuple(v) for m2d in train_image for v in m2d )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread('train/masks/1406.png',0)\n",
    "retval, threshold = cv2.threshold(img, 150, 1, cv2.THRESH_BINARY)\n",
    "plt.imshow(threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
